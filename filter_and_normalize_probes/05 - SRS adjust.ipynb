{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled Robust Sigmoid normalization (SRS)\n",
    "\n",
    "In this script, we normalize expression data using Ben Fulcher's scaled robust sigmoid normalization (SRS). We load data from all donors in the Allen Human Brain Atlas and normalize them via SRS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Initially, import needed libraries and define some enviromnent variables. \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('/home/mike/projects/PyGEST'))\n",
    "\n",
    "# Explicitly specify directories up front.\n",
    "base_dir = '.'\n",
    "ge_dir = '/data'\n",
    "\n",
    "# Get Call data from all subjects and combine it all.\n",
    "subs = ['H03511009', 'H03511012', 'H03511015', 'H03511016', 'H03512001', 'H03512002', ]\n",
    "\n",
    "sub_samples = {}\n",
    "srs_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 19:35:20 [INFO] | PyGEST has initialized logging, and is running on host 'cardano'\n",
      "2019-12-05 19:35:20 [INFO] | Found 9 donors in /data/sourcedata/participants.tsv\n"
     ]
    }
   ],
   "source": [
    "import pygest as ge\n",
    "data = ge.Data(ge_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define a useful formatter for time-stamping. \"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "def now_string():\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading H03511009's data.\n",
      "slab_type\n",
      "BS     26\n",
      "CB     42\n",
      "CX    295\n",
      "Name: slab_type, dtype: int64\n",
      "  58,692 probes by 363 samples\n",
      "  H03511009 expression has mean of 5.234, sd of 2.960, iqr of (2.40 to 7.32) = 4.924\n",
      "Reading H03511012's data.\n",
      "slab_type\n",
      "BS     80\n",
      "CB     48\n",
      "CX    401\n",
      "Name: slab_type, dtype: int64\n",
      "  58,692 probes by 529 samples\n",
      "  H03511012 expression has mean of 5.248, sd of 3.049, iqr of (2.43 to 7.44) = 5.008\n",
      "Reading H03511015's data.\n",
      "slab_type\n",
      "BS     79\n",
      "CB     62\n",
      "CX    329\n",
      "Name: slab_type, dtype: int64\n",
      "  58,692 probes by 470 samples\n",
      "  H03511015 expression has mean of 5.237, sd of 3.157, iqr of (2.38 to 7.49) = 5.108\n",
      "Reading H03511016's data.\n",
      "slab_type\n",
      "BS     59\n",
      "CB     80\n",
      "CX    362\n",
      "Name: slab_type, dtype: int64\n",
      "  58,692 probes by 501 samples\n",
      "  H03511016 expression has mean of 5.228, sd of 3.109, iqr of (2.56 to 7.42) = 4.863\n",
      "Reading H03512001's data.\n",
      "slab_type\n",
      "BS    154\n",
      "CB     53\n",
      "CX    739\n",
      "Name: slab_type, dtype: int64\n",
      "  58,692 probes by 946 samples\n",
      "  H03512001 expression has mean of 5.217, sd of 2.918, iqr of (2.49 to 7.27) = 4.784\n",
      "Reading H03512002's data.\n",
      "slab_type\n",
      "BS    188\n",
      "CB     83\n",
      "CX    622\n",
      "Name: slab_type, dtype: int64\n",
      "  58,692 probes by 893 samples\n",
      "  H03512002 expression has mean of 5.240, sd of 2.964, iqr of (2.49 to 7.29) = 4.803\n"
     ]
    }
   ],
   "source": [
    "call_list = []\n",
    "expr_list = []\n",
    "for sub in subs:\n",
    "    # Load data for each sub\n",
    "    print(\"Reading {}'s data.\".format(sub))\n",
    "    annot = pd.read_csv(os.path.join(ge_dir, \"sourcedata/sub-{}/expr/SampleAnnot.csv\".format(sub)))\n",
    "    calls = pd.read_csv(os.path.join(ge_dir, \"sourcedata/sub-{}/expr/PACall.csv\".format(sub)),\n",
    "                        header=None, index_col=0)\n",
    "    expr = pd.read_csv(os.path.join(ge_dir, \"sourcedata/sub-{}/expr/MicroarrayExpression.csv\".format(sub)),\n",
    "                       header=None, index_col=0)\n",
    "    \n",
    "    # Store a reference to each dataframe\n",
    "    sub_samples[sub] = list(annot['well_id'])\n",
    "    print(annot.groupby('slab_type')['slab_type'].count())\n",
    "    calls.columns = sub_samples[sub]\n",
    "    call_list.append(calls)\n",
    "    # call_list.append(calls.loc[:, annot[annot['slab_type'] == 'CX']['well_id']])\n",
    "    expr.columns = sub_samples[sub]\n",
    "    print(\"  {:,} probes by {:,} samples\".format(expr.shape[0], expr.shape[1]))\n",
    "    expr_list.append(expr)\n",
    "    \n",
    "    # Determine quartile values, intra-quartile range\n",
    "    ravelled = expr.values.ravel()\n",
    "    q75, q25 = np.percentile(ravelled, [75, 25])\n",
    "    print(\"  {} expression has mean of {:0.3f}, sd of {:0.3f}, iqr of ({:0.2f} to {:0.2f}) = {:0.3f}\".format(\n",
    "        sub, np.mean(ravelled), np.std(ravelled), q25, q75, q75 - q25\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calls is 58,692 x 3,702 'CX' samples. Expression is all 58,692 x 3,702\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Concat call and expr data together into a single dataframe for each data type. \"\"\"\n",
    "\n",
    "calls = pd.concat(call_list, axis=1)\n",
    "call_stats = pd.DataFrame(index=calls.index, columns=['num_called', ],\n",
    "    data = calls.apply(sum, axis=1),\n",
    ")\n",
    "call_stats['pct_called'] = call_stats['num_called'] / len(calls.columns)\n",
    "\n",
    "expression = pd.concat(expr_list, axis=1)\n",
    "\n",
    "print(\"Calls is {:,} x {:,} 'CX' samples. Expression is all {:,} x {:,}\".format(\n",
    "    calls.shape[0], calls.shape[1], expression.shape[0], expression.shape[1],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cortical expression has mean of 5.232, sd of 3.009, iqr of (2.47 to 7.35) = 4.883\n",
      "Overall expression has mean of 5.232, sd of 3.009, iqr of (2.47 to 7.35) = 4.883\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Report on distribution of expression values. \"\"\"\n",
    "\n",
    "ravelled = expression.loc[:, calls.columns].values.ravel()\n",
    "q75, q25 = np.percentile(ravelled, [75, 25])\n",
    "print(\"Cortical expression has mean of {:0.3f}, sd of {:0.3f}, iqr of ({:0.2f} to {:0.2f}) = {:0.3f}\".format(\n",
    "    np.mean(ravelled), np.std(ravelled), q25, q75, q75 - q25\n",
    "))\n",
    "\n",
    "ravelled = expression.values.ravel()\n",
    "q75, q25 = np.percentile(ravelled, [75, 25])\n",
    "print(\"Overall expression has mean of {:0.3f}, sd of {:0.3f}, iqr of ({:0.2f} to {:0.2f}) = {:0.3f}\".format(\n",
    "    np.mean(ravelled), np.std(ravelled), q25, q75, q75 - q25\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define some useful functions for later. \"\"\"\n",
    "\n",
    "def easy_chars(desc, x):\n",
    "    \"\"\" Return a string describing the distribution of x. \"\"\"\n",
    "    \n",
    "    q75, q25 = np.percentile(x, [75, 25])\n",
    "    return \"{}: min {:0.3f} - 25% @ {:0.3f} - mean {:0.3f}, median {:0.3f} - 75% @ {:0.3f} - max {:0.3f}\".format(\n",
    "        desc, min(x), q25, np.mean(x), np.median(x), q75, max(x)\n",
    "    )\n",
    "\n",
    "def dist_trio_plot(raw, transformed, scaled):\n",
    "    \"\"\" Return a figure and three-axes tuple of distplots for three matrices \"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(6, 6))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    sns.distplot(raw, ax=ax1)\n",
    "    ax1.set_ylabel(\"Raw\")\n",
    "    ax1.set_title(easy_chars(\"Raw\", raw))\n",
    "    \n",
    "    sns.distplot(transformed, ax=ax2)\n",
    "    ax2.set_ylabel(\"RS\")\n",
    "    ax2.set_title(easy_chars(\"RS\", transformed))\n",
    "\n",
    "    sns.distplot(scaled, ax=ax3)\n",
    "    ax3.set_ylabel(\"SRS\")\n",
    "    ax3.set_title(easy_chars(\"SRS\", scaled))\n",
    "    \n",
    "    return fig, (ax1, ax2, ax3)\n",
    "\n",
    "\n",
    "def srs_reg_plot(raw, transformed, scaled, max_points=2**16):\n",
    "    \"\"\" Return a figure with transformed and scaled regressed against raw. \"\"\"\n",
    "    \n",
    "    # Max out at 'max_points' points per vector. It takes way too long with tens of millions of points to plot.\n",
    "    smallest_length = min(len(raw), len(transformed), len(scaled))\n",
    "    idx = np.random.choice(range(smallest_length), min(max_points, smallest_length))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    \n",
    "    sns.regplot(raw[idx], srs_ravelled[idx], color='gray', scatter_kws={'s': 1}, ax=ax)\n",
    "    sns.regplot(raw[idx], scaled_srs_ravelled[idx], color='blue', scatter_kws={'s': 1}, ax=ax)\n",
    "    \n",
    "    return fig, ax\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SRS-transform of H03511009 @ 2019-12-05 14:48:21\n",
      "  Originally, H03511009 has [58,692 x 363] values (21,305,196 edges). SRS has [58,692 x 363] (21,305,196)\n",
      "  Raw: min 1.408 - 25% @ 2.401 - mean 5.234, median 4.986 - 75% @ 7.325 - max 18.586\n",
      "   RS: min 0.273 - 25% @ 0.330 - mean 0.511, median 0.500 - 75% @ 0.655 - max 0.977\n",
      "  SRS: min 0.000 - 25% @ 0.081 - mean 0.338, median 0.323 - 75% @ 0.543 - max 1.000\n",
      "      2019-12-05 14:49:29: wrote H03511009_dists.png\n",
      "      2019-12-05 14:49:37: wrote H03511009_regress.png\n",
      "Starting SRS-transform of H03511012 @ 2019-12-05 14:49:37\n",
      "  Originally, H03511012 has [58,692 x 529] values (31,048,068 edges). SRS has [58,692 x 529] (31,048,068)\n",
      "  Raw: min 1.101 - 25% @ 2.429 - mean 5.248, median 5.103 - 75% @ 7.438 - max 18.134\n",
      "   RS: min 0.254 - 25% @ 0.327 - mean 0.505, median 0.500 - 75% @ 0.652 - max 0.971\n",
      "  SRS: min 0.000 - 25% @ 0.102 - mean 0.350, median 0.343 - 75% @ 0.556 - max 1.000\n",
      "      2019-12-05 14:51:13: wrote H03511012_dists.png\n",
      "      2019-12-05 14:51:22: wrote H03511012_regress.png\n",
      "Starting SRS-transform of H03511015 @ 2019-12-05 14:51:22\n",
      "  Originally, H03511015 has [58,692 x 470] values (27,585,240 edges). SRS has [58,692 x 470] (27,585,240)\n",
      "  Raw: min 0.743 - 25% @ 2.384 - mean 5.237, median 5.143 - 75% @ 7.492 - max 18.244\n",
      "   RS: min 0.238 - 25% @ 0.325 - mean 0.502, median 0.500 - 75% @ 0.650 - max 0.970\n",
      "  SRS: min 0.000 - 25% @ 0.119 - mean 0.361, median 0.358 - 75% @ 0.564 - max 1.000\n",
      "      2019-12-05 14:52:48: wrote H03511015_dists.png\n",
      "      2019-12-05 14:52:57: wrote H03511015_regress.png\n",
      "Starting SRS-transform of H03511016 @ 2019-12-05 14:52:57\n",
      "  Originally, H03511016 has [58,692 x 501] values (29,404,692 edges). SRS has [58,692 x 501] (29,404,692)\n",
      "  Raw: min 0.674 - 25% @ 2.561 - mean 5.228, median 5.165 - 75% @ 7.424 - max 18.316\n",
      "   RS: min 0.223 - 25% @ 0.327 - mean 0.501, median 0.500 - 75% @ 0.652 - max 0.975\n",
      "  SRS: min 0.000 - 25% @ 0.138 - mean 0.369, median 0.368 - 75% @ 0.570 - max 1.000\n",
      "      2019-12-05 14:54:29: wrote H03511016_dists.png\n",
      "      2019-12-05 14:54:38: wrote H03511016_regress.png\n",
      "Starting SRS-transform of H03512001 @ 2019-12-05 14:54:38\n",
      "  Originally, H03512001 has [58,692 x 946] values (55,522,632 edges). SRS has [58,692 x 946] (55,522,632)\n",
      "  Raw: min 1.473 - 25% @ 2.485 - mean 5.217, median 4.915 - 75% @ 7.269 - max 18.382\n",
      "   RS: min 0.275 - 25% @ 0.335 - mean 0.514, median 0.500 - 75% @ 0.660 - max 0.978\n",
      "  SRS: min 0.000 - 25% @ 0.086 - mean 0.340, median 0.320 - 75% @ 0.548 - max 1.000\n",
      "      2019-12-05 14:57:29: wrote H03512001_dists.png\n",
      "      2019-12-05 14:57:41: wrote H03512001_regress.png\n",
      "Starting SRS-transform of H03512002 @ 2019-12-05 14:57:41\n",
      "  Originally, H03512002 has [58,692 x 893] values (52,411,956 edges). SRS has [58,692 x 893] (52,411,956)\n",
      "  Raw: min 1.279 - 25% @ 2.490 - mean 5.240, median 5.027 - 75% @ 7.292 - max 18.526\n",
      "   RS: min 0.259 - 25% @ 0.329 - mean 0.509, median 0.500 - 75% @ 0.654 - max 0.978\n",
      "  SRS: min 0.000 - 25% @ 0.098 - mean 0.348, median 0.336 - 75% @ 0.550 - max 1.000\n",
      "      2019-12-05 15:00:21: wrote H03512002_dists.png\n",
      "      2019-12-05 15:00:33: wrote H03512002_regress.png\n",
      "Overall, EXPR has [58,692 x 3,702] values (217,277,784 edges). SRS has [58,692 x 3,702] (217,277,784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, lets adjust everything\n",
    "sns.set_style(\"white\")\n",
    "sns.despine(left=True)\n",
    "srs_list = []\n",
    "for i, sub in enumerate(subs):\n",
    "    print(\"Starting SRS-transform of {} @ {}\".format(sub, now_string()))\n",
    "\n",
    "    # Pre-compute some necessary stats about our current dataset\n",
    "    ravelled = expr_list[i].values.ravel()\n",
    "    min_x = min(ravelled)\n",
    "    max_x = max(ravelled)\n",
    "    med_x = np.median(ravelled)\n",
    "    q75, q25 = np.percentile(ravelled, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    # The Scalable Robust Sigmoid normalization\n",
    "    # Transform it first\n",
    "    srs_expr = expr_list[i].applymap(lambda x: (1 / (1 + math.exp((-1.35 * (x - med_x)) / iqr))))\n",
    "    srs_ravelled = srs_expr.values.ravel()\n",
    "    min_srs = min(srs_ravelled)\n",
    "    max_srs = max(srs_ravelled)\n",
    "    \n",
    "    # Then scale it to fit between 0 and 1\n",
    "    srs_expr = srs_expr.applymap(lambda x: (x - min_srs) / (max_srs - min_srs))\n",
    "    srs_list.append(srs_expr)\n",
    "    scaled_srs_ravelled = srs_expr.values.ravel()\n",
    "    \n",
    "    print(\"  Originally, {} has [{:,} x {:,}] values ({:,} edges). SRS has [{:,} x {:,}] ({:,})\".format(\n",
    "        sub,\n",
    "        expr_list[i].shape[0], expr_list[i].shape[1], len(ravelled),\n",
    "        srs_expr.shape[0], srs_expr.shape[1], len(scaled_srs_ravelled),\n",
    "    ))\n",
    "    \n",
    "    # Plot the distributions for comparisons\n",
    "    fig, axes = dist_trio_plot(ravelled, srs_ravelled, scaled_srs_ravelled)\n",
    "    print(\"  \" + easy_chars(\"Raw\", ravelled))\n",
    "    print(\"  \" + easy_chars(\" RS\", srs_ravelled))\n",
    "    print(\"  \" + easy_chars(\"SRS\", scaled_srs_ravelled))\n",
    "    fig.suptitle(sub)\n",
    "    fig.savefig(os.path.join(\".\", \"{}_dists.png\".format(sub)))\n",
    "    plt.close(fig)\n",
    "    print(\"      {}: wrote {}_dists.png\".format(now_string(), sub))\n",
    "    \n",
    "    # Plot the raw vs srs data, but only a sample of a million points each (out of tens of millions)\n",
    "    fig, ax = srs_reg_plot(ravelled, srs_ravelled, scaled_srs_ravelled)\n",
    "    fig.suptitle(sub)\n",
    "    fig.savefig(os.path.join(\".\", \"{}_regress.png\".format(sub)))\n",
    "    plt.close(fig)\n",
    "    print(\"      {}: wrote {}_regress.png\".format(now_string(), sub))\n",
    "\n",
    "    # Save the data for later use\n",
    "    # srs_expr.to_pickle(os.path.join(ge_dir, \"cache/{}-exprsrs.df\".format(sub)))\n",
    "    # srs_expr.to_csv(os.path.join(ge_dir, \"sourcedata/sub-{}/expr/ExprSRS.csv\".format(sub)), header=False)\n",
    "\n",
    "expression_srs = pd.concat(srs_list, axis=1)\n",
    "expression_srs.to_pickle(os.path.join(ge_dir, \"cache/expression-srs.df\"))\n",
    "print(\"Overall, EXPR has [{:,} x {:,}] values ({:,} edges). SRS has [{:,} x {:,}] ({:,})\".format(\n",
    "    expression.shape[0], expression.shape[1], len(expression.values.ravel()),\n",
    "    expression_srs.shape[0], expression_srs.shape[1], len(expression_srs.values.ravel()),\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. (58692, 363)\n",
      "1. (58692, 529)\n",
      "2. (58692, 470)\n",
      "3. (58692, 501)\n",
      "4. (58692, 946)\n",
      "5. (58692, 893)\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(srs_list):\n",
    "    print(\"{}. {}\".format(i, x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, EXPR has [58,692 x 3,702] values (217,277,784 edges). SRS has [58,692 x 3,702] (217,277,784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall, EXPR has [{:,} x {:,}] values ({:,} edges). SRS has [{:,} x {:,}] ({:,})\".format(\n",
    "    expression.shape[0], expression.shape[1], len(expression.values.ravel()),\n",
    "    expression_srs.shape[0], expression_srs.shape[1], len(expression_srs.values.ravel()),\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58692, 3702)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11281</th>\n",
       "      <th>11305</th>\n",
       "      <th>11289</th>\n",
       "      <th>11335</th>\n",
       "      <th>11319</th>\n",
       "      <th>11263</th>\n",
       "      <th>11326</th>\n",
       "      <th>11318</th>\n",
       "      <th>11310</th>\n",
       "      <th>11302</th>\n",
       "      <th>...</th>\n",
       "      <th>7082</th>\n",
       "      <th>7090</th>\n",
       "      <th>7098</th>\n",
       "      <th>7011</th>\n",
       "      <th>7009</th>\n",
       "      <th>7017</th>\n",
       "      <th>7025</th>\n",
       "      <th>7033</th>\n",
       "      <th>7041</th>\n",
       "      <th>7057</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1058685</th>\n",
       "      <td>3.501077</td>\n",
       "      <td>4.154173</td>\n",
       "      <td>4.103324</td>\n",
       "      <td>3.962034</td>\n",
       "      <td>3.607175</td>\n",
       "      <td>3.397071</td>\n",
       "      <td>4.238925</td>\n",
       "      <td>3.220545</td>\n",
       "      <td>3.347516</td>\n",
       "      <td>4.094927</td>\n",
       "      <td>...</td>\n",
       "      <td>2.938440</td>\n",
       "      <td>2.912970</td>\n",
       "      <td>2.062344</td>\n",
       "      <td>3.655761</td>\n",
       "      <td>2.715837</td>\n",
       "      <td>4.274668</td>\n",
       "      <td>3.759001</td>\n",
       "      <td>4.903928</td>\n",
       "      <td>4.258150</td>\n",
       "      <td>4.079339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058684</th>\n",
       "      <td>1.757962</td>\n",
       "      <td>1.775427</td>\n",
       "      <td>1.858134</td>\n",
       "      <td>2.655145</td>\n",
       "      <td>1.896092</td>\n",
       "      <td>1.865290</td>\n",
       "      <td>1.659177</td>\n",
       "      <td>1.867601</td>\n",
       "      <td>1.843686</td>\n",
       "      <td>1.618922</td>\n",
       "      <td>...</td>\n",
       "      <td>1.336530</td>\n",
       "      <td>1.338208</td>\n",
       "      <td>1.317621</td>\n",
       "      <td>1.577733</td>\n",
       "      <td>1.677115</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>1.410152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058683</th>\n",
       "      <td>1.832017</td>\n",
       "      <td>1.975964</td>\n",
       "      <td>2.030700</td>\n",
       "      <td>1.862528</td>\n",
       "      <td>2.190454</td>\n",
       "      <td>2.049008</td>\n",
       "      <td>1.812967</td>\n",
       "      <td>2.142825</td>\n",
       "      <td>2.101910</td>\n",
       "      <td>1.892518</td>\n",
       "      <td>...</td>\n",
       "      <td>1.408085</td>\n",
       "      <td>1.430103</td>\n",
       "      <td>1.416651</td>\n",
       "      <td>1.691274</td>\n",
       "      <td>1.794972</td>\n",
       "      <td>1.338397</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>1.561965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058682</th>\n",
       "      <td>4.682878</td>\n",
       "      <td>5.480787</td>\n",
       "      <td>5.136348</td>\n",
       "      <td>5.477912</td>\n",
       "      <td>5.413002</td>\n",
       "      <td>5.105746</td>\n",
       "      <td>4.917350</td>\n",
       "      <td>5.037718</td>\n",
       "      <td>4.954490</td>\n",
       "      <td>5.064677</td>\n",
       "      <td>...</td>\n",
       "      <td>5.375030</td>\n",
       "      <td>5.398929</td>\n",
       "      <td>4.305211</td>\n",
       "      <td>4.235528</td>\n",
       "      <td>4.032939</td>\n",
       "      <td>4.471348</td>\n",
       "      <td>4.053165</td>\n",
       "      <td>4.226554</td>\n",
       "      <td>4.287815</td>\n",
       "      <td>4.940261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058681</th>\n",
       "      <td>6.198028</td>\n",
       "      <td>6.838466</td>\n",
       "      <td>6.646096</td>\n",
       "      <td>6.745124</td>\n",
       "      <td>6.366537</td>\n",
       "      <td>6.382501</td>\n",
       "      <td>6.277766</td>\n",
       "      <td>6.840333</td>\n",
       "      <td>7.023353</td>\n",
       "      <td>6.435251</td>\n",
       "      <td>...</td>\n",
       "      <td>6.660846</td>\n",
       "      <td>6.435792</td>\n",
       "      <td>6.539584</td>\n",
       "      <td>6.131654</td>\n",
       "      <td>6.471048</td>\n",
       "      <td>6.130729</td>\n",
       "      <td>6.492402</td>\n",
       "      <td>5.759537</td>\n",
       "      <td>5.760315</td>\n",
       "      <td>6.530532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071207</th>\n",
       "      <td>5.655763</td>\n",
       "      <td>5.823679</td>\n",
       "      <td>5.300496</td>\n",
       "      <td>5.352596</td>\n",
       "      <td>5.223130</td>\n",
       "      <td>5.374505</td>\n",
       "      <td>5.507863</td>\n",
       "      <td>5.577939</td>\n",
       "      <td>5.118923</td>\n",
       "      <td>5.437017</td>\n",
       "      <td>...</td>\n",
       "      <td>4.938741</td>\n",
       "      <td>5.338355</td>\n",
       "      <td>5.238756</td>\n",
       "      <td>4.274668</td>\n",
       "      <td>4.756083</td>\n",
       "      <td>5.166071</td>\n",
       "      <td>5.537803</td>\n",
       "      <td>5.302679</td>\n",
       "      <td>4.821446</td>\n",
       "      <td>5.491417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071208</th>\n",
       "      <td>6.084677</td>\n",
       "      <td>5.616215</td>\n",
       "      <td>5.807900</td>\n",
       "      <td>6.074535</td>\n",
       "      <td>4.197354</td>\n",
       "      <td>5.639088</td>\n",
       "      <td>6.039145</td>\n",
       "      <td>5.714244</td>\n",
       "      <td>4.597356</td>\n",
       "      <td>5.314180</td>\n",
       "      <td>...</td>\n",
       "      <td>6.517703</td>\n",
       "      <td>5.998020</td>\n",
       "      <td>7.099504</td>\n",
       "      <td>6.539101</td>\n",
       "      <td>6.328269</td>\n",
       "      <td>6.361749</td>\n",
       "      <td>6.912770</td>\n",
       "      <td>6.973036</td>\n",
       "      <td>6.913132</td>\n",
       "      <td>6.656428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071209</th>\n",
       "      <td>1.825304</td>\n",
       "      <td>2.078818</td>\n",
       "      <td>2.543738</td>\n",
       "      <td>2.614573</td>\n",
       "      <td>2.089824</td>\n",
       "      <td>1.770973</td>\n",
       "      <td>2.365111</td>\n",
       "      <td>2.042799</td>\n",
       "      <td>1.917748</td>\n",
       "      <td>1.612720</td>\n",
       "      <td>...</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>1.448611</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>1.541985</td>\n",
       "      <td>1.696660</td>\n",
       "      <td>1.557243</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>1.279049</td>\n",
       "      <td>2.076494</td>\n",
       "      <td>1.361727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071210</th>\n",
       "      <td>5.072246</td>\n",
       "      <td>5.317859</td>\n",
       "      <td>4.854512</td>\n",
       "      <td>4.704538</td>\n",
       "      <td>4.577459</td>\n",
       "      <td>5.316336</td>\n",
       "      <td>5.184707</td>\n",
       "      <td>5.546673</td>\n",
       "      <td>5.204318</td>\n",
       "      <td>5.271943</td>\n",
       "      <td>...</td>\n",
       "      <td>5.757539</td>\n",
       "      <td>2.485872</td>\n",
       "      <td>6.081343</td>\n",
       "      <td>3.880230</td>\n",
       "      <td>5.429549</td>\n",
       "      <td>5.313957</td>\n",
       "      <td>7.088099</td>\n",
       "      <td>7.256872</td>\n",
       "      <td>7.133733</td>\n",
       "      <td>7.068572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071211</th>\n",
       "      <td>5.359524</td>\n",
       "      <td>4.953978</td>\n",
       "      <td>4.154945</td>\n",
       "      <td>5.566792</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>5.019680</td>\n",
       "      <td>4.554634</td>\n",
       "      <td>4.064994</td>\n",
       "      <td>3.520271</td>\n",
       "      <td>5.246785</td>\n",
       "      <td>...</td>\n",
       "      <td>5.564499</td>\n",
       "      <td>5.507484</td>\n",
       "      <td>7.770212</td>\n",
       "      <td>4.999496</td>\n",
       "      <td>5.409435</td>\n",
       "      <td>7.064279</td>\n",
       "      <td>6.628172</td>\n",
       "      <td>6.961658</td>\n",
       "      <td>7.130235</td>\n",
       "      <td>4.966900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58692 rows × 3702 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            11281     11305     11289     11335     11319     11263     11326  \\\n",
       "0                                                                               \n",
       "1058685  3.501077  4.154173  4.103324  3.962034  3.607175  3.397071  4.238925   \n",
       "1058684  1.757962  1.775427  1.858134  2.655145  1.896092  1.865290  1.659177   \n",
       "1058683  1.832017  1.975964  2.030700  1.862528  2.190454  2.049008  1.812967   \n",
       "1058682  4.682878  5.480787  5.136348  5.477912  5.413002  5.105746  4.917350   \n",
       "1058681  6.198028  6.838466  6.646096  6.745124  6.366537  6.382501  6.277766   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1071207  5.655763  5.823679  5.300496  5.352596  5.223130  5.374505  5.507863   \n",
       "1071208  6.084677  5.616215  5.807900  6.074535  4.197354  5.639088  6.039145   \n",
       "1071209  1.825304  2.078818  2.543738  2.614573  2.089824  1.770973  2.365111   \n",
       "1071210  5.072246  5.317859  4.854512  4.704538  4.577459  5.316336  5.184707   \n",
       "1071211  5.359524  4.953978  4.154945  5.566792  3.971858  5.019680  4.554634   \n",
       "\n",
       "            11318     11310     11302  ...     7082      7090      7098   \\\n",
       "0                                      ...                                 \n",
       "1058685  3.220545  3.347516  4.094927  ...  2.938440  2.912970  2.062344   \n",
       "1058684  1.867601  1.843686  1.618922  ...  1.336530  1.338208  1.317621   \n",
       "1058683  2.142825  2.101910  1.892518  ...  1.408085  1.430103  1.416651   \n",
       "1058682  5.037718  4.954490  5.064677  ...  5.375030  5.398929  4.305211   \n",
       "1058681  6.840333  7.023353  6.435251  ...  6.660846  6.435792  6.539584   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "1071207  5.577939  5.118923  5.437017  ...  4.938741  5.338355  5.238756   \n",
       "1071208  5.714244  4.597356  5.314180  ...  6.517703  5.998020  7.099504   \n",
       "1071209  2.042799  1.917748  1.612720  ...  1.279049  1.448611  1.279049   \n",
       "1071210  5.546673  5.204318  5.271943  ...  5.757539  2.485872  6.081343   \n",
       "1071211  4.064994  3.520271  5.246785  ...  5.564499  5.507484  7.770212   \n",
       "\n",
       "            7011      7009      7017      7025      7033      7041      7057   \n",
       "0                                                                              \n",
       "1058685  3.655761  2.715837  4.274668  3.759001  4.903928  4.258150  4.079339  \n",
       "1058684  1.577733  1.677115  1.279049  1.279049  1.279049  1.279049  1.410152  \n",
       "1058683  1.691274  1.794972  1.338397  1.279049  1.279049  1.279049  1.561965  \n",
       "1058682  4.235528  4.032939  4.471348  4.053165  4.226554  4.287815  4.940261  \n",
       "1058681  6.131654  6.471048  6.130729  6.492402  5.759537  5.760315  6.530532  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "1071207  4.274668  4.756083  5.166071  5.537803  5.302679  4.821446  5.491417  \n",
       "1071208  6.539101  6.328269  6.361749  6.912770  6.973036  6.913132  6.656428  \n",
       "1071209  1.541985  1.696660  1.557243  1.279049  1.279049  2.076494  1.361727  \n",
       "1071210  3.880230  5.429549  5.313957  7.088099  7.256872  7.133733  7.068572  \n",
       "1071211  4.999496  5.409435  7.064279  6.628172  6.961658  7.130235  4.966900  \n",
       "\n",
       "[58692 rows x 3702 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(expression.shape)\n",
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58692, 3702)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11281</th>\n",
       "      <th>11305</th>\n",
       "      <th>11289</th>\n",
       "      <th>11335</th>\n",
       "      <th>11319</th>\n",
       "      <th>11263</th>\n",
       "      <th>11326</th>\n",
       "      <th>11318</th>\n",
       "      <th>11310</th>\n",
       "      <th>11302</th>\n",
       "      <th>...</th>\n",
       "      <th>7082</th>\n",
       "      <th>7090</th>\n",
       "      <th>7098</th>\n",
       "      <th>7011</th>\n",
       "      <th>7009</th>\n",
       "      <th>7017</th>\n",
       "      <th>7025</th>\n",
       "      <th>7033</th>\n",
       "      <th>7041</th>\n",
       "      <th>7057</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1058685</th>\n",
       "      <td>0.180336</td>\n",
       "      <td>0.242325</td>\n",
       "      <td>0.237441</td>\n",
       "      <td>0.223914</td>\n",
       "      <td>0.190280</td>\n",
       "      <td>0.170643</td>\n",
       "      <td>0.250483</td>\n",
       "      <td>0.154330</td>\n",
       "      <td>0.166046</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137263</td>\n",
       "      <td>0.134981</td>\n",
       "      <td>0.061698</td>\n",
       "      <td>0.203297</td>\n",
       "      <td>0.117475</td>\n",
       "      <td>0.262387</td>\n",
       "      <td>0.213042</td>\n",
       "      <td>0.323578</td>\n",
       "      <td>0.260792</td>\n",
       "      <td>0.243579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058684</th>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.029047</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>0.103407</td>\n",
       "      <td>0.038853</td>\n",
       "      <td>0.036337</td>\n",
       "      <td>0.019726</td>\n",
       "      <td>0.036526</td>\n",
       "      <td>0.034578</td>\n",
       "      <td>0.016527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.022820</td>\n",
       "      <td>0.030609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058683</th>\n",
       "      <td>0.033630</td>\n",
       "      <td>0.045416</td>\n",
       "      <td>0.049946</td>\n",
       "      <td>0.036112</td>\n",
       "      <td>0.063317</td>\n",
       "      <td>0.051468</td>\n",
       "      <td>0.032084</td>\n",
       "      <td>0.059308</td>\n",
       "      <td>0.055879</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009749</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.031727</td>\n",
       "      <td>0.039971</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058682</th>\n",
       "      <td>0.293484</td>\n",
       "      <td>0.371100</td>\n",
       "      <td>0.337628</td>\n",
       "      <td>0.370822</td>\n",
       "      <td>0.364525</td>\n",
       "      <td>0.334648</td>\n",
       "      <td>0.316302</td>\n",
       "      <td>0.328024</td>\n",
       "      <td>0.319919</td>\n",
       "      <td>0.330649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369564</td>\n",
       "      <td>0.371892</td>\n",
       "      <td>0.265338</td>\n",
       "      <td>0.258609</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.281435</td>\n",
       "      <td>0.241069</td>\n",
       "      <td>0.257743</td>\n",
       "      <td>0.263657</td>\n",
       "      <td>0.327126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058681</th>\n",
       "      <td>0.439950</td>\n",
       "      <td>0.499614</td>\n",
       "      <td>0.481926</td>\n",
       "      <td>0.491059</td>\n",
       "      <td>0.455853</td>\n",
       "      <td>0.457352</td>\n",
       "      <td>0.447491</td>\n",
       "      <td>0.499784</td>\n",
       "      <td>0.516397</td>\n",
       "      <td>0.462299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492435</td>\n",
       "      <td>0.471430</td>\n",
       "      <td>0.481152</td>\n",
       "      <td>0.442635</td>\n",
       "      <td>0.474739</td>\n",
       "      <td>0.442547</td>\n",
       "      <td>0.476740</td>\n",
       "      <td>0.406896</td>\n",
       "      <td>0.406971</td>\n",
       "      <td>0.480307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071207</th>\n",
       "      <td>0.388032</td>\n",
       "      <td>0.404211</td>\n",
       "      <td>0.353597</td>\n",
       "      <td>0.358660</td>\n",
       "      <td>0.346073</td>\n",
       "      <td>0.360788</td>\n",
       "      <td>0.373724</td>\n",
       "      <td>0.380509</td>\n",
       "      <td>0.335931</td>\n",
       "      <td>0.366856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326978</td>\n",
       "      <td>0.365990</td>\n",
       "      <td>0.356275</td>\n",
       "      <td>0.262387</td>\n",
       "      <td>0.309149</td>\n",
       "      <td>0.349180</td>\n",
       "      <td>0.385404</td>\n",
       "      <td>0.362511</td>\n",
       "      <td>0.315526</td>\n",
       "      <td>0.380895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071208</th>\n",
       "      <td>0.429184</td>\n",
       "      <td>0.384211</td>\n",
       "      <td>0.402694</td>\n",
       "      <td>0.428218</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>0.386421</td>\n",
       "      <td>0.424845</td>\n",
       "      <td>0.393675</td>\n",
       "      <td>0.285173</td>\n",
       "      <td>0.354927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479107</td>\n",
       "      <td>0.429857</td>\n",
       "      <td>0.532491</td>\n",
       "      <td>0.481107</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.464460</td>\n",
       "      <td>0.515594</td>\n",
       "      <td>0.521074</td>\n",
       "      <td>0.515627</td>\n",
       "      <td>0.492026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071209</th>\n",
       "      <td>0.033084</td>\n",
       "      <td>0.053951</td>\n",
       "      <td>0.093641</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.054869</td>\n",
       "      <td>0.028688</td>\n",
       "      <td>0.078182</td>\n",
       "      <td>0.050951</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.032152</td>\n",
       "      <td>0.021226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062866</td>\n",
       "      <td>0.006227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071210</th>\n",
       "      <td>0.331386</td>\n",
       "      <td>0.355285</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.295590</td>\n",
       "      <td>0.283241</td>\n",
       "      <td>0.355137</td>\n",
       "      <td>0.342335</td>\n",
       "      <td>0.377483</td>\n",
       "      <td>0.344243</td>\n",
       "      <td>0.350821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406703</td>\n",
       "      <td>0.097436</td>\n",
       "      <td>0.437833</td>\n",
       "      <td>0.224548</td>\n",
       "      <td>0.374874</td>\n",
       "      <td>0.363611</td>\n",
       "      <td>0.531466</td>\n",
       "      <td>0.546538</td>\n",
       "      <td>0.535562</td>\n",
       "      <td>0.529709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071211</th>\n",
       "      <td>0.359333</td>\n",
       "      <td>0.319869</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.379431</td>\n",
       "      <td>0.224852</td>\n",
       "      <td>0.326268</td>\n",
       "      <td>0.281026</td>\n",
       "      <td>0.233765</td>\n",
       "      <td>0.182131</td>\n",
       "      <td>0.348374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387998</td>\n",
       "      <td>0.382457</td>\n",
       "      <td>0.591008</td>\n",
       "      <td>0.332911</td>\n",
       "      <td>0.372916</td>\n",
       "      <td>0.529322</td>\n",
       "      <td>0.489403</td>\n",
       "      <td>0.520041</td>\n",
       "      <td>0.535248</td>\n",
       "      <td>0.329728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58692 rows × 3702 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            11281     11305     11289     11335     11319     11263     11326  \\\n",
       "0                                                                               \n",
       "1058685  0.180336  0.242325  0.237441  0.223914  0.190280  0.170643  0.250483   \n",
       "1058684  0.027639  0.029047  0.035754  0.103407  0.038853  0.036337  0.019726   \n",
       "1058683  0.033630  0.045416  0.049946  0.036112  0.063317  0.051468  0.032084   \n",
       "1058682  0.293484  0.371100  0.337628  0.370822  0.364525  0.334648  0.316302   \n",
       "1058681  0.439950  0.499614  0.481926  0.491059  0.455853  0.457352  0.447491   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1071207  0.388032  0.404211  0.353597  0.358660  0.346073  0.360788  0.373724   \n",
       "1071208  0.429184  0.384211  0.402694  0.428218  0.246479  0.386421  0.424845   \n",
       "1071209  0.033084  0.053951  0.093641  0.099839  0.054869  0.028688  0.078182   \n",
       "1071210  0.331386  0.355285  0.310183  0.295590  0.283241  0.355137  0.342335   \n",
       "1071211  0.359333  0.319869  0.242400  0.379431  0.224852  0.326268  0.281026   \n",
       "\n",
       "            11318     11310     11302  ...     7082      7090      7098   \\\n",
       "0                                      ...                                 \n",
       "1058685  0.154330  0.166046  0.236635  ...  0.137263  0.134981  0.061698   \n",
       "1058684  0.036526  0.034578  0.016527  ...  0.004322  0.004449  0.002896   \n",
       "1058683  0.059308  0.055879  0.038561  ...  0.009749  0.011429  0.010402   \n",
       "1058682  0.328024  0.319919  0.330649  ...  0.369564  0.371892  0.265338   \n",
       "1058681  0.499784  0.516397  0.462299  ...  0.492435  0.471430  0.481152   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "1071207  0.380509  0.335931  0.366856  ...  0.326978  0.365990  0.356275   \n",
       "1071208  0.393675  0.285173  0.354927  ...  0.479107  0.429857  0.532491   \n",
       "1071209  0.050951  0.040627  0.016036  ...  0.000000  0.012845  0.000000   \n",
       "1071210  0.377483  0.344243  0.350821  ...  0.406703  0.097436  0.437833   \n",
       "1071211  0.233765  0.182131  0.348374  ...  0.387998  0.382457  0.591008   \n",
       "\n",
       "            7011      7009      7017      7025      7033      7041      7057   \n",
       "0                                                                              \n",
       "1058685  0.203297  0.117475  0.262387  0.213042  0.323578  0.260792  0.243579  \n",
       "1058684  0.022820  0.030609  0.000000  0.000000  0.000000  0.000000  0.009906  \n",
       "1058683  0.031727  0.039971  0.004463  0.000000  0.000000  0.000000  0.021593  \n",
       "1058682  0.258609  0.239130  0.281435  0.241069  0.257743  0.263657  0.327126  \n",
       "1058681  0.442635  0.474739  0.442547  0.476740  0.406896  0.406971  0.480307  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "1071207  0.262387  0.309149  0.349180  0.385404  0.362511  0.315526  0.380895  \n",
       "1071208  0.481107  0.461300  0.464460  0.515594  0.521074  0.515627  0.492026  \n",
       "1071209  0.020042  0.032152  0.021226  0.000000  0.000000  0.062866  0.006227  \n",
       "1071210  0.224548  0.374874  0.363611  0.531466  0.546538  0.535562  0.529709  \n",
       "1071211  0.332911  0.372916  0.529322  0.489403  0.520041  0.535248  0.329728  \n",
       "\n",
       "[58692 rows x 3702 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(expression_srs.shape)\n",
    "expression_srs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting regression plot of all data at 2019-12-05 16:10:20\n",
      "      wrote raw_vs_srs.png at 2019-12-05 16:14:10\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Compare entirety of raw expression to SRS-normalized values. \"\"\"\n",
    "\n",
    "print(\"Starting regression plot of all data at {}\".format(now_string()))\n",
    "n = min(len(expression.values.ravel()), 2**21)\n",
    "idx = np.random.choice(range(len(expression.values.ravel())), n)\n",
    "x_vals = expression.values.ravel()[idx]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "sns.regplot(x=x_vals, y=expression_srs.values.ravel()[idx], scatter_kws={'s': 1}, ax=ax)\n",
    "ax.set_xlabel(\"Expression\")\n",
    "ax.set_ylabel(\"SRS-Normalized\")\n",
    "fig.suptitle(\"All Expression\")\n",
    "fig.savefig(os.path.join(\".\", \"raw_vs_srs.png\"))\n",
    "plt.close(fig)\n",
    "print(\"      wrote raw_vs_srs.png at {}\".format(now_string()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting split halves\n",
    "\n",
    "Each split half is loaded directly from file rather than extracted from full expression dataframe. To use split halves, we'll open each one, figure out its contents, and make a comparable file using SRS-normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Functions copied from PyGEST to split the same way, but with pre-determined split lists. \"\"\"\n",
    "\n",
    "import csv\n",
    "from pygest.rawdata.glasser import glasser_parcel_map\n",
    "\n",
    "def average_expr_per_parcel(wellid_expression, parcel_map):\n",
    "    \"\"\" Average expression values over all wellids in each parcel_map-defined parcel. \"\"\"\n",
    "\n",
    "    parcels = pd.DataFrame(\n",
    "        data={'parcel': [parcel_map[x] for x in wellid_expression.columns]},\n",
    "        index=wellid_expression.columns\n",
    "    )\n",
    "    parcel_means = {}\n",
    "    for parcel in sorted(list(set(parcel_map.values()))):\n",
    "        parcel_idx = parcels[parcels['parcel'] == parcel].index\n",
    "        if len(parcel_idx) > 0:\n",
    "            parcel_means[parcel] = wellid_expression.loc[:, parcel_idx].mean(axis=1)\n",
    "\n",
    "    return pd.DataFrame(data=parcel_means)\n",
    "\n",
    "\n",
    "def split_file_name(d, ext):\n",
    "    \"\"\" Return the filename for a split-half dataframe.\n",
    "        :param dict d: A dictionary containing the parts of the split-half filename.\n",
    "        :param str ext: 'csv' for list of wellids, 'df' for dataframes\n",
    "    \"\"\"\n",
    "    if ext == 'df':\n",
    "        return \"parcelby-{parby}_splitby-{splby}.df\".format_map(d)\n",
    "    elif ext == 'csv':\n",
    "        return \"{parby}s_splitby-{splby}.csv\".format_map(d)\n",
    "    else:\n",
    "        raise KeyError(\"Split file names only handle 'csv' or 'df' files.\")\n",
    "\n",
    "        \n",
    "def write_subset(phase, splitby, seed, df_wellid, df_parcel):\n",
    "    \"\"\" Write out three files for samples, expression, and each parcellated expression. \"\"\"\n",
    "\n",
    "    d = {'splby': splitby, 'phase': phase, 'seed': seed}\n",
    "    base_path = os.path.join(\n",
    "        ge_dir, 'splits', \"sub-all_hem-A_samp-glasser_prob-fornito\",\n",
    "        \"batch-{}{:05}\".format(phase, seed),\n",
    "    )\n",
    "    os.makedirs(os.path.abspath(base_path), exist_ok=True)\n",
    "\n",
    "    def write_a_split(df, parcelby):\n",
    "        df.to_pickle(os.path.join(base_path, \"parcelby-{}_splitby-{}.srs.df\".format(parcelby, splitby)))\n",
    "        print(\"  final {}-split {} set is {} probes x {} {}s, {} {} wellids.\".format(\n",
    "            splitby, phase, df.shape[0], df.shape[1], parcelby,\n",
    "            'from' if splitby == 'wellid' else 'comprising', len(df.columns)\n",
    "        ))\n",
    "\n",
    "    write_a_split(df_wellid, 'wellid')\n",
    "    write_a_split(df_parcel, 'glasser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 200, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 162 glassers, from 162 wellids.\n",
      "Split 200, train phase, by glasser\n",
      "  724 wellids\n",
      "  final glasser-split train set is 15745 probes x 724 wellids, comprising 724 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 200, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 160 glassers, from 160 wellids.\n",
      "Split 200, test phase, by glasser\n",
      "  556 wellids\n",
      "  final glasser-split test set is 15745 probes x 556 wellids, comprising 556 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 201, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 161 glassers, from 161 wellids.\n",
      "Split 201, train phase, by glasser\n",
      "  673 wellids\n",
      "  final glasser-split train set is 15745 probes x 673 wellids, comprising 673 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 201, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 161 glassers, from 161 wellids.\n",
      "Split 201, test phase, by glasser\n",
      "  607 wellids\n",
      "  final glasser-split test set is 15745 probes x 607 wellids, comprising 607 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 202, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 158 glassers, from 158 wellids.\n",
      "Split 202, train phase, by glasser\n",
      "  701 wellids\n",
      "  final glasser-split train set is 15745 probes x 701 wellids, comprising 701 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 202, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 164 glassers, from 164 wellids.\n",
      "Split 202, test phase, by glasser\n",
      "  579 wellids\n",
      "  final glasser-split test set is 15745 probes x 579 wellids, comprising 579 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 203, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 166 glassers, from 166 wellids.\n",
      "Split 203, train phase, by glasser\n",
      "  709 wellids\n",
      "  final glasser-split train set is 15745 probes x 709 wellids, comprising 709 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 203, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 157 glassers, from 157 wellids.\n",
      "Split 203, test phase, by glasser\n",
      "  571 wellids\n",
      "  final glasser-split test set is 15745 probes x 571 wellids, comprising 571 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 204, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 162 glassers, from 162 wellids.\n",
      "Split 204, train phase, by glasser\n",
      "  628 wellids\n",
      "  final glasser-split train set is 15745 probes x 628 wellids, comprising 628 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 204, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 163 glassers, from 163 wellids.\n",
      "Split 204, test phase, by glasser\n",
      "  652 wellids\n",
      "  final glasser-split test set is 15745 probes x 652 wellids, comprising 652 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 205, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 156 glassers, from 156 wellids.\n",
      "Split 205, train phase, by glasser\n",
      "  720 wellids\n",
      "  final glasser-split train set is 15745 probes x 720 wellids, comprising 720 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 205, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 165 glassers, from 165 wellids.\n",
      "Split 205, test phase, by glasser\n",
      "  560 wellids\n",
      "  final glasser-split test set is 15745 probes x 560 wellids, comprising 560 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 206, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 165 glassers, from 165 wellids.\n",
      "Split 206, train phase, by glasser\n",
      "  648 wellids\n",
      "  final glasser-split train set is 15745 probes x 648 wellids, comprising 648 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 206, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 155 glassers, from 155 wellids.\n",
      "Split 206, test phase, by glasser\n",
      "  632 wellids\n",
      "  final glasser-split test set is 15745 probes x 632 wellids, comprising 632 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 207, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 163 glassers, from 163 wellids.\n",
      "Split 207, train phase, by glasser\n",
      "  575 wellids\n",
      "  final glasser-split train set is 15745 probes x 575 wellids, comprising 575 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 207, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 159 glassers, from 159 wellids.\n",
      "Split 207, test phase, by glasser\n",
      "  705 wellids\n",
      "  final glasser-split test set is 15745 probes x 705 wellids, comprising 705 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 208, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 163 glassers, from 163 wellids.\n",
      "Split 208, train phase, by glasser\n",
      "  595 wellids\n",
      "  final glasser-split train set is 15745 probes x 595 wellids, comprising 595 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 208, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 162 glassers, from 162 wellids.\n",
      "Split 208, test phase, by glasser\n",
      "  685 wellids\n",
      "  final glasser-split test set is 15745 probes x 685 wellids, comprising 685 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 209, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 166 glassers, from 166 wellids.\n",
      "Split 209, train phase, by glasser\n",
      "  637 wellids\n",
      "  final glasser-split train set is 15745 probes x 637 wellids, comprising 637 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 209, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 160 glassers, from 160 wellids.\n",
      "Split 209, test phase, by glasser\n",
      "  643 wellids\n",
      "  final glasser-split test set is 15745 probes x 643 wellids, comprising 643 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 210, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 158 glassers, from 158 wellids.\n",
      "Split 210, train phase, by glasser\n",
      "  681 wellids\n",
      "  final glasser-split train set is 15745 probes x 681 wellids, comprising 681 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 210, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 162 glassers, from 162 wellids.\n",
      "Split 210, test phase, by glasser\n",
      "  599 wellids\n",
      "  final glasser-split test set is 15745 probes x 599 wellids, comprising 599 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 211, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 160 glassers, from 160 wellids.\n",
      "Split 211, train phase, by glasser\n",
      "  614 wellids\n",
      "  final glasser-split train set is 15745 probes x 614 wellids, comprising 614 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 211, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 155 glassers, from 155 wellids.\n",
      "Split 211, test phase, by glasser\n",
      "  666 wellids\n",
      "  final glasser-split test set is 15745 probes x 666 wellids, comprising 666 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 212, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 163 glassers, from 163 wellids.\n",
      "Split 212, train phase, by glasser\n",
      "  629 wellids\n",
      "  final glasser-split train set is 15745 probes x 629 wellids, comprising 629 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 212, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 158 glassers, from 158 wellids.\n",
      "Split 212, test phase, by glasser\n",
      "  651 wellids\n",
      "  final glasser-split test set is 15745 probes x 651 wellids, comprising 651 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 213, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 162 glassers, from 162 wellids.\n",
      "Split 213, train phase, by glasser\n",
      "  618 wellids\n",
      "  final glasser-split train set is 15745 probes x 618 wellids, comprising 618 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 213, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 162 glassers, from 162 wellids.\n",
      "Split 213, test phase, by glasser\n",
      "  662 wellids\n",
      "  final glasser-split test set is 15745 probes x 662 wellids, comprising 662 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 214, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 162 glassers, from 162 wellids.\n",
      "Split 214, train phase, by glasser\n",
      "  689 wellids\n",
      "  final glasser-split train set is 15745 probes x 689 wellids, comprising 689 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 214, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 165 glassers, from 165 wellids.\n",
      "Split 214, test phase, by glasser\n",
      "  591 wellids\n",
      "  final glasser-split test set is 15745 probes x 591 wellids, comprising 591 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n",
      "Split 215, train phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split train set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split train set is 15745 probes x 162 glassers, from 162 wellids.\n",
      "Split 215, train phase, by glasser\n",
      "  710 wellids\n",
      "  final glasser-split train set is 15745 probes x 710 wellids, comprising 710 wellids.\n",
      "  final glasser-split train set is 15745 probes x 88 glassers, comprising 88 wellids.\n",
      "Split 215, test phase, by wellid\n",
      "  640 wellids\n",
      "  final wellid-split test set is 15745 probes x 640 wellids, from 640 wellids.\n",
      "  final wellid-split test set is 15745 probes x 158 glassers, from 158 wellids.\n",
      "Split 215, test phase, by glasser\n",
      "  570 wellids\n",
      "  final glasser-split test set is 15745 probes x 570 wellids, comprising 570 wellids.\n",
      "  final glasser-split test set is 15745 probes x 89 glassers, comprising 89 wellids.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Cycle through split halves. \"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "fornito_probes = sorted(list(data.probes(\"fornito\").index))\n",
    "\n",
    "for split_seed in range(200, 216):\n",
    "    for phase in [\"train\", \"test\", ]:\n",
    "        split_path = os.path.join(ge_dir, \"splits\", \"sub-all_hem-A_samp-glasser_prob-fornito\", \"batch-{}00{}\".format(phase, split_seed))\n",
    "        for split in [\"wellid\", \"glasser\", ]:\n",
    "            print(\"Split {}, {} phase, by {}\".format(split_seed, phase, split))\n",
    "            wellid_file = \"wellids_splitby-{}.csv\".format(split)\n",
    "            wellids = sorted(list(pd.read_csv(os.path.join(split_path, wellid_file), header=None).values.ravel()))\n",
    "            print(\"  {:,} wellids\".format(len(wellids)))\n",
    "            expr = expression_srs.loc[fornito_probes, wellids]\n",
    "            expr.index.rename(\"probe_id\", inplace=True)\n",
    "            expr_parcellated = average_expr_per_parcel(expr, glasser_parcel_map)\n",
    "            write_subset(phase, split, split_seed, expr, expr_parcellated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot a few of the files, old vs new, to ensure new files appear as expected. \"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "dfa = None\n",
    "dfb = None\n",
    "\n",
    "test_path = \"/data/splits/sub-all_hem-A_samp-glasser_prob-fornito/batch-train00207\"\n",
    "for p in [\"wellid\", \"glasser\" ]:\n",
    "    for s in [\"wellid\", \"glasser\", ]:\n",
    "        with open(os.path.join(test_path, \"parcelby-{}_splitby-{}.df\".format(p, s)), \"rb\") as f:\n",
    "            dfa = pickle.load(f)\n",
    "            dfa = dfa.sort_index()\n",
    "            dfa = dfa.loc[:, sorted(list(dfa.columns))]\n",
    "        with open(os.path.join(test_path, \"parcelby-{}_splitby-{}.srs.df\".format(p, s)), \"rb\") as f:\n",
    "            dfb = pickle.load(f)\n",
    "            dfb = dfb.sort_index()\n",
    "            dfb = dfb.loc[:, sorted(list(dfb.columns))]\n",
    "        idx = np.random.choice(range(min(len(dfa), len(dfb))), min(len(dfa), len(dfb), 2**20))\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.regplot(dfa.values.ravel()[idx], dfb.values.ravel()[idx], ax=ax)\n",
    "        fig.savefig(os.path.join(test_path, \"p-{}_s-{}.png\".format(p, s)))\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schmidt_geconn",
   "language": "python",
   "name": "schmidt_geconn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
