{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate p-values for each gene\n",
    "\n",
    "The whack-a-probe optimization/training process results in a ranked list of genes where the gene's ranking is its only quantitative attribute. But we would like to report the probability we discovered any particular gene purely by chance, a p-value. To do this, we compare the average ranking each gene achieved in 16 split-half real data sets against the ranking the gene achieved in 256 runs of each of three permutation algorithms. A gene that was consistently ranked higher in real data than it was in shuffled data would have a low p-value.\n",
    "\n",
    "$$p = {times gene ranked higher in permuation} \\over 256$$\n",
    "\n",
    "A second approach counts each individual real ranking (rather than averages) against each individual shuffled ranking, which is 4,096 comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define some lists for looping. \"\"\"\n",
    "masks = ['00', '16', '32', '64', ]\n",
    "shuffles = [\"agno\", \"dist\", \"edge\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak for 00 at 72 +/- 18\n",
      "     00 agno at 88 +/- 25\n",
      "     00 dist at 79 +/- 24\n",
      "     00 edge at 45 +/- 12\n",
      "Peak for 16 at 72 +/- 14\n",
      "     16 agno at 89 +/- 25\n",
      "     16 dist at 79 +/- 24\n",
      "     16 edge at 46 +/- 12\n",
      "Peak for 32 at 77 +/- 14\n",
      "     32 agno at 90 +/- 25\n",
      "     32 dist at 78 +/- 23\n",
      "     32 edge at 46 +/- 13\n",
      "Peak for 64 at 69 +/- 17\n",
      "     64 agno at 89 +/- 26\n",
      "     64 dist at 78 +/- 23\n",
      "     64 edge at 49 +/- 14\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load up the data, preprocessed by the ge_data_manager project.\n",
    "    We won't use this to generate rankings, but we can see quickly\n",
    "    where the peaks are in each run. \"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "pre_calc_results = {}\n",
    "for mask in masks:\n",
    "    with open(\"/data/plots/cache/hcpww{}speak_ol_post.df\".format(mask), \"br\") as f:\n",
    "        pre_calc_results[mask] = pickle.load(f)\n",
    "        derivatives = pre_calc_results[mask][pre_calc_results[mask]['shuffle'] == 'none']\n",
    "        print(\"Peak for {} at {:,} +/- {:0.0f}\".format(\n",
    "            mask,\n",
    "            15745 - int(derivatives['peak'].mean()),\n",
    "            derivatives['peak'].std(),\n",
    "        ))\n",
    "        for shuffle in shuffles:\n",
    "            shuffled = pre_calc_results[mask][pre_calc_results[mask]['shuffle'] == shuffle]\n",
    "            print(\"     {} {} at {:,} +/- {:0.0f}\".format(\n",
    "                mask, shuffle,\n",
    "                15745 - int(shuffled['peak'].mean()),\n",
    "                shuffled['peak'].std(),\n",
    "            ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to import all rankings into a single dataframe. Rank them all. Then calculate p-values. We calculate the old intensive way first, then add onto that dataframe with the faster vectorized method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Modified from ge_data_manager to include shuffled data,\n",
    "    the ranked_probes function iterates over result tsvs, ranking genes and saving them\n",
    "    into a single dataframe. \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pygest import algorithms\n",
    "from pygest.convenience import bids_val\n",
    "from pygest.rawdata import miscellaneous\n",
    "\n",
    "\n",
    "def name_from_path(path):\n",
    "    \"\"\" Extract critical pieces from the path to return an abbreviated column name.\n",
    "        Three items differ in each path: 4 shuffle-types, 16 splits, 16 seeds (plus None). \"\"\"\n",
    "    \n",
    "    shuffle = bids_val(\"shuffle\", path)\n",
    "    if shuffle == \"random\":\n",
    "        shuffle = \"agno\" \n",
    "    if shuffle == \"actual\":\n",
    "        shuffle = \"real\" \n",
    "    \n",
    "    batch = bids_val(\"batch\", path)[-3:]\n",
    "    seed = bids_val(\"seed\", path)[-3:]\n",
    "    \n",
    "    return \"{}-{}-{}\".format(shuffle, batch, seed)\n",
    "\n",
    "    \n",
    "def ranked_probes(tsvs, top):\n",
    "    \"\"\" Go through the files provided, at the threshold specified, and report probes in all files. \"\"\"\n",
    "\n",
    "    report_progress_on_items = range(int(len(tsvs)/10), len(tsvs), int(len(tsvs)/10))\n",
    "    all_rankings = pd.DataFrame()\n",
    "    for i, tsv in enumerate(tsvs):\n",
    "        df = pd.read_csv(tsv, sep='\\t')\n",
    "        rankings = pd.Series(data=df.index, index=df['probe_id'], name=name_from_path(tsv))\n",
    "        if i == 0:\n",
    "            all_rankings = pd.DataFrame(data=rankings)\n",
    "        else:\n",
    "            all_rankings[rankings.name] = rankings\n",
    "        # if i in report_progress_on_items:\n",
    "        #     print(\"Ranked {} of {} and counting...\".format(i, len(tsvs)))\n",
    "        if i == len(tsvs):\n",
    "            print(\"    ranked all probes in {} results.\".format(i + 1))\n",
    "    all_rankings['mean'] = all_rankings.mean(axis=1)\n",
    "    all_rankings['entrez_id'] = all_rankings.index.map(miscellaneous.map_pid_to_eid_fornito)\n",
    "    return all_rankings.sort_values('mean', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Rank probes/genes for each and every run. \"\"\"\n",
    "\n",
    "rankings = {}\n",
    "for mask in masks:\n",
    "    tsv_files = pre_calc_results[mask]['path']\n",
    "    rankings[mask] = ranked_probes(tsv_files, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" We can borrow the id-to-symbol map from PyGEST.\n",
    "    (although it would be better to build a reproducible routine to extract it from updated human_gene_info files.) \"\"\"\n",
    "\n",
    "from pygest import convenience\n",
    "\n",
    "id_to_symbol_map = convenience.create_id_to_symbol_map()\n",
    "for mask in masks:\n",
    "    rankings[mask]['gene_symbol'] = rankings[mask]['entrez_id'].map(id_to_symbol_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Determine, for each probe/gene, how likely it is for a real ranking to be higher than a shuffled ranking.\n",
    "    This is the c-style, expensive, 4k-comparison approach. \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def p_probe(probe_id, df):\n",
    "    \"\"\" Return probability (p-value) a real rank is higher than shuffled. \"\"\"\n",
    "    \n",
    "    ps = {}\n",
    "    real_runs = [c for c in df.columns if \"real\" in c]\n",
    "    for shuf in [\"agno\", \"dist\", \"edge\", ]:\n",
    "        shuffled_runs = [c for c in df.columns if shuf in c]\n",
    "\n",
    "        n_better = 0\n",
    "        n_worse = 0\n",
    "        n_total = 0\n",
    "        for real in df.loc[probe_id, real_runs]:\n",
    "            for baseline in df.loc[probe_id, shuffled_runs]:\n",
    "                n_total += 1\n",
    "                if real < baseline:\n",
    "                    n_better += 1\n",
    "                else:\n",
    "                    n_worse += 1\n",
    "            # print(\"    {} vs {} of {}\".format(n_better, n_worse, n_total))\n",
    "        ps[shuf] = n_worse / n_total\n",
    "\n",
    "        # print(\"Mean real rank = {:,} vs mean {} rank of {:,}; {:,} better, {:,} worse, out of {:,}; p = {:0.3f}\".format(\n",
    "        #     int(np.mean(df.loc[probe_id, real_runs])), shuf, int(np.mean(df.loc[probe_id, shuffled_runs])),\n",
    "        #     n_better, n_worse, n_total, ps[shuf]\n",
    "        # ))\n",
    "        \n",
    "    return ps[\"agno\"], ps[\"dist\"], ps[\"edge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Manually sample a few genes that came out in the prior algorithm as good, ok, and bad.\\n    Use just this small subset to rapidly prototype and check old vs new algorithms. '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Manually sample a few genes that came out in the prior algorithm as good, ok, and bad.\n",
    "    Use just this small subset to rapidly prototype and check old vs new algorithms. \"\"\" \n",
    "\n",
    "# selected_ids = [57622, 8178, 728882, 10605, 23395, 1482, 9865, ]\n",
    "# selected_ids = set(selected_ids).union(set(rankings[\"16\"].sample(16)['entrez_id']))\n",
    "# selected_probes = list(rankings[\"16\"][rankings[\"16\"][\"entrez_id\"].isin(selected_ids)][\"entrez_id\"].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-01 20:14:11.948781\n",
      "Calculating p-values for 00mm-masked results.\n",
      "2019-12-01 20:28:36.431538\n",
      "Calculating p-values for 16mm-masked results.\n",
      "2019-12-01 20:43:19.067604\n",
      "Calculating p-values for 32mm-masked results.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Calculate p-values for real vs each of three shuffle types.\n",
    "    This employs the c-style time intenstive process that performs ~4000 comparisons per gene. \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "df_p_values = {}\n",
    "for mask in masks:\n",
    "    print(datetime.datetime.now())\n",
    "    p_values = {}\n",
    "    print(\"Calculating p-values for {}mm-masked results.\".format(mask))\n",
    "    for pid in rankings[mask].index:  # replace me with selected_probes to limit how many genes are tested.\n",
    "        p_a, p_d, p_e = p_probe(pid, rankings[mask])\n",
    "        p_values[pid] = {\n",
    "            'entrez_id': int(rankings[mask].loc[pid, 'entrez_id']),\n",
    "            'gene_symbol': rankings[mask].loc[pid, 'gene_symbol'],\n",
    "            'old_agno': p_a,\n",
    "            'old_dist': p_d,\n",
    "            'old_edge': p_e,\n",
    "        }\n",
    "    df_p_values[mask] = pd.DataFrame(data=p_values).T\n",
    "    df_p_values[mask]['entrez_id'] = df_p_values[mask]['entrez_id'].astype(int)\n",
    "    # df_p_values[mask] = df_p_values[mask].set_index('entrez_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Calculate p values by simply counting how many shuffled rankings are better\n",
    "    than the average real ranking. This is only 256 comparisons. \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for mask in masks:\n",
    "    reals = rankings[mask].loc[:, [x for x in rankings[mask].columns if \"real\" in x]]\n",
    "    real_means = reals.apply(np.mean, axis=1)\n",
    "\n",
    "    for shuffle in shuffles:\n",
    "        permuted_rankings = rankings[mask].loc[:, [x for x in rankings[mask].columns if shuffle in x]]\n",
    "        hits = permuted_rankings.lt(real_means, axis=0)\n",
    "        df_p_values[mask]['new_' + shuffle] = hits.sum(axis=1) / hits.count(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for mask in masks:\n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(9,3), sharey=True)\n",
    "    sns.regplot(x=\"old_agno\", y=\"new_agno\", data=df_p_values[mask], ax=axes[0])\n",
    "    sns.regplot(x=\"old_dist\", y=\"new_dist\", data=df_p_values[mask], ax=axes[1])\n",
    "    sns.regplot(x=\"old_edge\", y=\"new_edge\", data=df_p_values[mask], ax=axes[2])\n",
    "    fig.savefig(\"./old_vs_new_p_{}.png\".format(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_values['32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define a kernel-density plot to assist in visualizing the distributions of rankings. \"\"\"\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flatten = lambda l: [x for y in l for x in y]\n",
    "\n",
    "def plot_entrez_id(entrez_id, rank_data, p_data, algo):\n",
    "    \"\"\" Plot ranking distributions for one entrez id. \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    real_list = flatten(rank_data[rank_data['entrez_id'] == entrez_id][[x for x in rank_data.columns if \"real\" in x]].values)\n",
    "    real_label = \"real\"\n",
    "    sns.distplot(real_list, ax=ax, kde_kws={\"color\": \"black\", \"label\": real_label}, hist_kws={\"color\": \"gray\"})\n",
    "    agno_list = flatten(rank_data[rank_data['entrez_id'] == entrez_id][[x for x in rank_data.columns if \"agno\" in x]].values)\n",
    "    agno_label = \"vs agno, p = {:0.5f}\".format(p_data.loc[entrez_id, algo + '_agno'])\n",
    "    sns.distplot(agno_list, ax=ax, kde_kws={\"color\": \"green\", \"label\": agno_label}, hist_kws={\"color\": \"lightgreen\"})\n",
    "    dist_list = flatten(rank_data[rank_data['entrez_id'] == entrez_id][[x for x in rank_data.columns if \"dist\" in x]].values)\n",
    "    dist_label = \"vs dist, p = {:0.5f}\".format(p_data.loc[entrez_id, algo + '_dist'])\n",
    "    sns.distplot(dist_list, ax=ax, kde_kws={\"color\": \"red\", \"label\": dist_label}, hist_kws={\"color\": \"mistyrose\"})\n",
    "    edge_list = flatten(rank_data[rank_data['entrez_id'] == entrez_id][[x for x in rank_data.columns if \"edge\" in x]].values)\n",
    "    edge_label = \"vs edge, p = {:0.5f}\".format(p_data.loc[entrez_id, algo + '_edge'])\n",
    "    sns.distplot(edge_list, ax=ax, kde_kws={\"color\": \"magenta\", \"label\": edge_label}, hist_kws={\"color\": \"lavenderblush\"})\n",
    "    fig.suptitle(\"Entrez ID {} ({} p)\".format(entrez_id, algo))\n",
    "    return fig, ax\n",
    "\n",
    "# f, a = plot_entrez_id(57622, rankings[\"16\"], df_p_values[\"16\"].set_index('entrez_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Save out a csv file with entrez ids ordered by p-value for each mask and shuffle type. \"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "for mask in masks:\n",
    "    for algo in [\"new\", \"old\", ]:\n",
    "        eids_all_good = set(df_p_values[mask]['entrez_id'])\n",
    "        eids_all_bad = set(df_p_values[mask]['entrez_id'])\n",
    "        for shuffle in shuffles:\n",
    "            print(\"{} {}_{} {:,} probes with p < 0.05\".format(\n",
    "                mask, algo, shuffle, (df_p_values[mask][algo + \"_\" + shuffle] < 0.05).sum()\n",
    "            ))\n",
    "            for id in [\"gene_symbol\", \"entrez_id\", ]:\n",
    "                df = df_p_values[mask][[id, algo + \"_\" + shuffle]].set_index(id).sort_values(algo + \"_\" + shuffle)\n",
    "                df = df.rename(columns={algo + \"_\" + shuffle: \"p\"})\n",
    "                df.to_csv(\"./hcpww{}s_{}_{}_p_by_{}.tsv\".format(mask, algo, shuffle, id), sep=\"\\t\")\n",
    "\n",
    "            eids_all_good = eids_all_good.intersection(set(df['p'][df['p'] < 0.05].index))\n",
    "            eids_all_bad = eids_all_bad.intersection(set(df['p'][df['p'] >= 0.05].index))\n",
    "\n",
    "        print(\"Mask {} has {} probes surviving all {} p-tests.\".format(mask, len(eids_all_good), algo))\n",
    "        print(\"    {}\".format(sorted(list(eids_all_good))[:12]))\n",
    "        eid_to_plot = random.sample(eids_all_good, 3)[0]\n",
    "        f, a = plot_entrez_id(eid_to_plot, rankings[mask], df_p_values[mask].set_index('entrez_id'), algo)\n",
    "        f.savefig(\"good_{}_{}.png\".format(mask, eid_to_plot))\n",
    "        f.clear()\n",
    "\n",
    "        print(\"Mask {} has {} probes failing all {} p-tests.\".format(mask, len(eids_all_bad), algo))\n",
    "        print(\"    {}\".format(sorted(list(eids_all_bad))[:12]))\n",
    "        eid_to_plot = random.sample(eids_all_bad, 3)[0]\n",
    "        f, a = plot_entrez_id(eid_to_plot, rankings[mask], df_p_values[mask].set_index('entrez_id'), algo)    \n",
    "        f.savefig(\"bad_{}_{}.png\".format(mask, eid_to_plot))\n",
    "        f.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" No longer necessary\n",
    "    This was written to convert an old csv format to tsv, but all current files are already tsv. \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "for mask in masks:\n",
    "    for shuffle in shuffles:\n",
    "        for p_algo in [\"new\", \"old\", ]:\n",
    "            filename = \"./hcpww{}s_{}_{}_p\".format(mask, p_algo, shuffle)\n",
    "            if os.path.isfile(filename + \".csv\"):\n",
    "                print(\"Converting {}\".format(filename))\n",
    "                df = pd.read_csv(filename + \".csv\", index_col=0)\n",
    "                df.to_csv(filename + \".tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schmidt_geconn",
   "language": "python",
   "name": "schmidt_geconn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
