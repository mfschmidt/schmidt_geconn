{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refresh ermineJ GO files and run it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Refresh ermineJ data\n",
    "\n",
    "Download and let python unzip the ontology and annotation files. ErmineJ can handle zipped files, but this allows us to dig into them out of curiosity if we like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Update these paths for fresh data before running GO.\n",
    "    If you enter the URL up to the final '/', without the file, you can browse and see modified dates.\n",
    "\"\"\"\n",
    "\n",
    "ontology = {\n",
    "    'url': 'http://archive.geneontology.org/latest-termdb/go_daily-termdb.rdf-xml.gz',\n",
    "    'path': './2019-07-09-erminej_go.rdf-xml',\n",
    "}\n",
    "\n",
    "annotation = {\n",
    "    'url': 'https://gemma.msl.ubc.ca/annots/Generic_human_ncbiIds_noParents.an.txt.gz',\n",
    "    'path': './2019-11-20-erminej_human_annotation_entrezid.txt',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Download a fresh version of each compressed file and save it decompressed. \"\"\"\n",
    "\n",
    "import urllib.request as request\n",
    "import gzip\n",
    "\n",
    "for data_file in [ontology, annotation, ]:\n",
    "    response = request.urlopen(data_file['url'])\n",
    "    with open(data_file['path'], \"wb\") as f:\n",
    "        f.write(gzip.decompress(response.read()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare a scored gene list\n",
    "\n",
    "We have tables of probes with average rankings across 32 split-quarters. This is what we want to feed ermineJ, but they are indexed by probe_id values, not gene labels. Convert probe_ids to gene_names, then save out as a tsv file for use by ermineJ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load four dataframes, one for each distance-mask, and save each in a format ermineJ can read. \"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "base_dir = \"/home/mike/ge_data\"\n",
    "masks = [\"00\", \"16\", \"32\", \"64\", ]\n",
    "rank_files = []\n",
    "os.makedirs(\"gene_scores\", exist_ok=True)\n",
    "\n",
    "dfs = {}\n",
    "for mask in masks:\n",
    "    # Determine variables\n",
    "    filename = \"hcpww{}ss4peak_ranked_full.csv\".format(mask)\n",
    "    filepath = os.path.join(base_dir, \"plots\", filename)\n",
    "\n",
    "    # Load data, and sort by mean ranking\n",
    "    dfs[mask] = pd.read_csv(filepath).sort_values('raw_mean', ascending=True).set_index('entrez_id')[['raw_mean']]\n",
    "    rank_file_path = \"gene_scores/mean_ranks_{}.tsv\".format(mask)\n",
    "    rank_files.append(rank_file_path)\n",
    "    dfs[mask].to_csv(rank_file_path, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execute ermineJ analyses\n",
    "\n",
    "The easiest way, perhaps, to do this is to use the java GUI to select an analysis and determine which options are the best bet. Then look at the text file saved out as results. It will have a full command with all options used toward the top of the output file. Use those options to seed the command below, then it can be re-run, looped over, etc. with different inputs or settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene ontology for gene_scores/mean_ranks_00.tsv took 24.7 seconds.\n",
      "Gene ontology for gene_scores/mean_ranks_16.tsv took 24.5 seconds.\n",
      "Gene ontology for gene_scores/mean_ranks_32.tsv took 25.2 seconds.\n",
      "Gene ontology for gene_scores/mean_ranks_64.tsv took 24.6 seconds.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Update paths to your own installation. Then this should just work. \"\"\"\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "\n",
    "os.makedirs(\"./results\", exist_ok=True)\n",
    "result_files = []\n",
    "\n",
    "for rank_file in rank_files:\n",
    "    start_time = time.time()\n",
    "    result_file = rank_file.replace(\"gene_scores\", \"results\").replace(\".tsv\", \"_erminej_gsr_results.txt\")\n",
    "    \n",
    "    # Run ermineJ\n",
    "    p = subprocess.run(\n",
    "        [\n",
    "            'ermineJ.sh',\n",
    "            '-d', '/home/mike/Dropbox/Projects/GE-Conn/gene_ontology/ermineJ.data',\n",
    "            '--annots', annotation['path'],\n",
    "            '--classFile', ontology['path'],\n",
    "            '--scoreFile', rank_file,\n",
    "            '--test', 'GSR',                 # Method for computing significance. GSR best for gene scores\n",
    "            '--mtc', 'FDR',                  # FDR indicates Benjamini-Hochberg corrections for false discovery rate\n",
    "            '--reps', 'BEST',                # If a gene has multiple scores in input, use BEST\n",
    "            '--genesOut',                    # Include gene symbols in output\n",
    "            '--minClassSize', '5',           # smallest gene set size to be considered\n",
    "            '--maxClassSize', '128',         # largest gene set size to be considered\n",
    "            '-aspects', 'BCM',               # Test against all three GO components\n",
    "            '-b', 'false',                   # Big is not better, rankings are low==good\n",
    "            '--logTrans', 'false',           # If we fed p-values, we would set this to true\n",
    "            '--output', result_file,\n",
    "        ],\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "    )\n",
    "    \n",
    "    # Write the log file\n",
    "    result_files.append(result_file)\n",
    "    with open(result_file.replace(\".txt\", \".log\"), \"w\") as f:\n",
    "        f.write(\"STDOUT:\\n\")\n",
    "        f.write(p.stdout.decode())\n",
    "        f.write(\"STDERR:\\n\")\n",
    "        f.write(p.stderr.decode())\n",
    "        \n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Gene ontology for {} took {:0.1f} seconds.\".format(rank_file, end_time - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a. Display results in this notebook\n",
    "\n",
    "We can parse the result files as tsv data after stripping headers and footers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create functions to manipulate ermineJ output \"\"\"\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def tsvify_erminej_result(result_file):\n",
    "    \"\"\" Take in a result from ermineJ and write it out with headers stripped. \"\"\"\n",
    "\n",
    "    tsv_file = result_file.replace(\".txt\", \".tsv\")\n",
    "    with open(result_file, \"r\") as f_in:\n",
    "        with open(tsv_file, \"w\") as f_out:\n",
    "            for i, line in enumerate(f_in):\n",
    "                head_match = re.search('^#!\\t', line)\n",
    "                if head_match:\n",
    "                    f_out.write(line[3:].rstrip() + \"\\n\")\n",
    "                data_match = re.search('^!\\t', line)\n",
    "                if data_match:\n",
    "                    f_out.write(line[2:].rstrip() + \"\\n\")\n",
    "    return tsv_file\n",
    "\n",
    "\n",
    "def describe_top_results(tsv_file, top_n=10):\n",
    "    \"\"\" Read a tsv-based results file and print results legibly. \"\"\"\n",
    "    \n",
    "    def describe_go_term(row):\n",
    "        import pdb; pdb.set_trace()\n",
    "        return \"{:<12}: {:<48} p{}\".format(\n",
    "            row['ID'], row['Name'],\n",
    "            \"={:0.5f}\".format(row['CorrectedPvalue']) if row['CorrectedPvalue'] > 0.00001 else \"<0.00001\"\n",
    "        )\n",
    "    \n",
    "    df = pd.read_csv(tsv_file, sep='\\t').sort_values('CorrectedPvalue', ascending=True)\n",
    "    df.loc[df['CorrectedPvalue'] < 0.05, :].iloc[:top_n, :].apply(lambda row: print(describe_go_term(row)), axis='columns')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tsv_file = \"results/mean_ranks_00_erminej_gsr_results.tsv\"\n",
    "df = pd.read_csv(tsv_file, sep='\\t').sort_values('CorrectedPvalue', ascending=True)\n",
    "df.loc[df['CorrectedPvalue'] < 0.5, :]\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Interpret and report on results. \"\"\"\n",
    "\n",
    "for result_file in result_files:\n",
    "    tsv_file = tsvify_erminej_result(result_file)\n",
    "    describe_top_results(tsv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. Explore results in ermineJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" You'll need to manually load the results into ermineJ to view them.\n",
    "    You may even have to manually select annotation and GO files (it seems to ignore these when using --gui)\n",
    "    After [start]ing, Ctrl-L to load results.\n",
    "\"\"\"\n",
    "\n",
    "p = subprocess.run(\n",
    "    [\n",
    "        'ermineJ.sh',\n",
    "        '-d', '/home/mike/Dropbox/Projects/GE-Conn/gene_ontology/ermineJ.data',\n",
    "        '--annots', annotation['path'],\n",
    "        '--classFile', ontology['path'],\n",
    "        '--gui',\n",
    "    ],\n",
    "    stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schmidt_geconn",
   "language": "python",
   "name": "schmidt_geconn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
