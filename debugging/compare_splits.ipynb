{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare two splits\n",
    "\n",
    "This can be run on two folders that should contain the same split (testing that the randomizer is behaving with the seed to create replicable results). Or two sets of splits can be compared to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define which split directories to compare. \"\"\"\n",
    "\n",
    "# These should contain identical splits\n",
    "base_a = \"/data/splits/sub-all_hem-A_samp-glasser_prob-fornito/batch-train00508\"\n",
    "base_b = \"/data/splits/sub-all_hem-A_samp-glasser_prob-fornito/batch-train00508b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def getdf(p):\n",
    "    \"\"\" Load and return a dataframe whether it's from a pickled df or a csv or tsv. \"\"\"\n",
    "    \n",
    "    if p[-3:] == \".df\":\n",
    "        with open(p, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    elif p[-4:] == \".csv\":\n",
    "        return pd.read_csv(p)\n",
    "    elif p[-4:] == \".tsv\":\n",
    "        return pd.read_csv(p, sep=\"\\t\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def report_comparison(a_df=None, b_df=None, a_label=\"a\", b_label=\"b\", common_label=\"_\"):\n",
    "    \"\"\" compare dataframes and return a description of their differences. \"\"\"\n",
    "    \n",
    "    n_match = len(set(a_df.columns).intersection(set(b_df.columns)))\n",
    "    n_possible = max(len(a_df.columns), len(b_df.columns))\n",
    "    match_string = \"{:,} / {:,} ids match\".format(n_match, n_possible)\n",
    "\n",
    "    rms_error = None\n",
    "    if (n_match == n_possible) and (a_df.shape == b_df.shape) and (len(a_df) > 0):\n",
    "        rms_error = sqrt(((a_df - b_df)**2).mean().mean())\n",
    "\n",
    "    equality_string = \"!=\"\n",
    "    if rms_error is not None and rms_error < 0.01:\n",
    "        equality_string = \"==\"\n",
    "    elif n_match == n_possible and len(a_df) == 0 and len(b_df) == 0:\n",
    "        equality_string = \"==\"\n",
    "\n",
    "    rms_string = \"\"\n",
    "    if rms_error is not None:\n",
    "        rms_string = \"; rms error {:5.2f}\".format(rms_error)\n",
    "\n",
    "    return \"\\n\".join([\n",
    "        \"{:<40} : {} : {}{}\".format(common_label, equality_string, match_string, rms_string),\n",
    "        \"{}{}: {:<12};  {}: {:<12}\".format(\" \" * 48, a_label, str(a_df.shape), b_label, str(b_df.shape)),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wellids_splitby-wellid.csv               : == : 320 / 320 ids match\n",
      "                                                0508: (0, 320)    ;  508b: (0, 320)    \n",
      "parcelby-wellid_splitby-wellid.raw.df    : == : 320 / 320 ids match; rms error  0.00\n",
      "                                                0508: (15745, 320);  508b: (15745, 320)\n",
      "parcelby-wellid_splitby-wellid.srs.df    : == : 320 / 320 ids match; rms error  0.00\n",
      "                                                0508: (15745, 320);  508b: (15745, 320)\n",
      "glassers_splitby-wellid.csv              : == : 132 / 132 ids match\n",
      "                                                0508: (0, 132)    ;  508b: (0, 132)    \n",
      "parcelby-glasser_splitby-wellid.raw.df   : == : 132 / 132 ids match; rms error  0.00\n",
      "                                                0508: (15745, 132);  508b: (15745, 132)\n",
      "parcelby-glasser_splitby-wellid.srs.df   : == : 132 / 132 ids match; rms error  0.00\n",
      "                                                0508: (15745, 132);  508b: (15745, 132)\n",
      "wellids_splitby-glasser.csv              : == : 330 / 330 ids match\n",
      "                                                0508: (0, 330)    ;  508b: (0, 330)    \n",
      "parcelby-wellid_splitby-glasser.raw.df   : == : 330 / 330 ids match; rms error  0.00\n",
      "                                                0508: (15745, 330);  508b: (15745, 330)\n",
      "parcelby-wellid_splitby-glasser.srs.df   : == : 330 / 330 ids match; rms error  0.00\n",
      "                                                0508: (15745, 330);  508b: (15745, 330)\n",
      "glassers_splitby-glasser.csv             : == : 44 / 44 ids match\n",
      "                                                0508: (0, 44)     ;  508b: (0, 44)     \n",
      "parcelby-glasser_splitby-glasser.raw.df  : == : 44 / 44 ids match; rms error  0.00\n",
      "                                                0508: (15745, 44) ;  508b: (15745, 44) \n",
      "parcelby-glasser_splitby-glasser.srs.df  : == : 44 / 44 ids match; rms error  0.00\n",
      "                                                0508: (15745, 44) ;  508b: (15745, 44) \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Compare each of the 12 files per folder against its counterpart and print the results. \"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "for S in ['wellid', 'glasser', ]:\n",
    "    for P in ['wellid', 'glasser', ]:\n",
    "        for F in [\"{}s_splitby-{}.csv\", \"parcelby-{}_splitby-{}.raw.df\", \"parcelby-{}_splitby-{}.srs.df\", ]:\n",
    "            filename = F.format(P, S)\n",
    "            df_a = getdf(os.path.join(base_a, filename))\n",
    "            df_b = getdf(os.path.join(base_b, filename))\n",
    "            \n",
    "            print(report_comparison(\n",
    "                a_df=df_a, a_label=base_a[-4:], \n",
    "                b_df=df_b, b_label=base_b[-4:],\n",
    "                common_label=filename\n",
    "            ))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parcelby-wellid_splitby-wellid           : != : 320 / 320 ids match; rms error  7.38\n",
      "                                                raw: (15745, 320);  srs: (15745, 320)\n",
      "parcelby-wellid_splitby-wellid           : != : 320 / 320 ids match; rms error  7.38\n",
      "                                                raw: (15745, 320);  srs: (15745, 320)\n",
      "parcelby-glasser_splitby-wellid          : != : 132 / 132 ids match; rms error  7.38\n",
      "                                                raw: (15745, 132);  srs: (15745, 132)\n",
      "parcelby-glasser_splitby-wellid          : != : 132 / 132 ids match; rms error  7.38\n",
      "                                                raw: (15745, 132);  srs: (15745, 132)\n",
      "parcelby-wellid_splitby-glasser          : != : 330 / 330 ids match; rms error  7.38\n",
      "                                                raw: (15745, 330);  srs: (15745, 330)\n",
      "parcelby-wellid_splitby-glasser          : != : 330 / 330 ids match; rms error  7.38\n",
      "                                                raw: (15745, 330);  srs: (15745, 330)\n",
      "parcelby-glasser_splitby-glasser         : != : 44 / 44 ids match; rms error  7.36\n",
      "                                                raw: (15745, 44) ;  srs: (15745, 44) \n",
      "parcelby-glasser_splitby-glasser         : != : 44 / 44 ids match; rms error  7.36\n",
      "                                                raw: (15745, 44) ;  srs: (15745, 44) \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Compare each of the raw/srs pairs against each other and print the results. \"\"\"\n",
    "\n",
    "for S in ['wellid', 'glasser', ]:\n",
    "    for P in ['wellid', 'glasser', ]:\n",
    "        for D in [base_a, base_b ]:\n",
    "            df_raw = getdf(os.path.join(D, \"parcelby-{}_splitby-{}.raw.df\".format(P, S)))\n",
    "            df_srs = getdf(os.path.join(D, \"parcelby-{}_splitby-{}.srs.df\".format(P, S)))\n",
    "            \n",
    "            print(report_comparison(\n",
    "                a_df=df_raw, a_label=\"raw\",\n",
    "                b_df=df_srs, b_label=\"srs\",\n",
    "                common_label=\"parcelby-{}_splitby-{}\".format(P, S)\n",
    "            ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the splits are actually the same, everything from the first loop should be equal in every way. Everything in the second loop should match ids, but not be equal. The 'raw' and 'srs' versions of the expression data will have the same wellid and probe labels, but values will have been adjusted. From spot-checking, it looks like root-mean-squared-error between raw and srs is in the ballpark of 7 or 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schmidt_geconn",
   "language": "python",
   "name": "schmidt_geconn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
